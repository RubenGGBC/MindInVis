import { ChatOpenAI } from '@langchain/openai';
import { HumanMessage, SystemMessage } from '@langchain/core/messages';

class OpenAIService {
  constructor() {
    if (!process.env.OPENAI_API_KEY) {
      console.error('‚ùå OPENAI_API_KEY not found in environment');
      throw new Error('OpenAI API key is required');
    }
    
    console.log('‚úì Initializing OpenAI service with gpt-3.5-turbo');
    this.llm = new ChatOpenAI({
      modelName: 'gpt-3.5-turbo',
      temperature: 0.7,
      maxTokens: 500,
      openAIApiKey: process.env.OPENAI_API_KEY
    });
    console.log('‚úì ChatOpenAI instance created');
  }

  /**
   * Generate child nodes based on parent node content and type
   * @param {string} nodeText - Content of the parent node
   * @param {string} nodeTipo - Type of parent node ('pregunta', 'respuesta', 'root')
   * @param {number} count - Number of nodes to generate (default: 3)
   * @returns {Promise<{nodes: Array<{text: string}>}>}
   */
  async generateNodes(nodeText, nodeTipo, count = 3) {
    try {
      console.log(`ü§ñ Generating ${count} nodes for "${nodeText}" (type: ${nodeTipo})`);
      
      const prompt = this._buildPrompt(nodeText, nodeTipo, count);
      console.log('üìù Prompt built, invoking LLM...');

      const response = await this.llm.invoke(prompt);
      console.log('‚úì LLM response received');

      const nodes = this._parseResponse(response.content);
      console.log(`‚úì Parsed ${nodes.length} nodes from response`);

      // Ensure we return exactly 'count' nodes (pad or trim as needed)
      const finalNodes = nodes.slice(0, count);
      while (finalNodes.length < count) {
        finalNodes.push({ text: `Concepto ${finalNodes.length + 1}` });
      }

      console.log(`‚úì Returning ${finalNodes.length} final nodes`);
      return { nodes: finalNodes };
    } catch (error) {
      console.error('‚ùå OpenAI generation error:', error.message);
      console.error('Full error:', error);
      throw new Error(`Failed to generate nodes: ${error.message}`);
    }
  }

  /**
   * Build prompt based on node type
   * @private
   */
  _buildPrompt(nodeText, nodeTipo, count) {
    if (nodeTipo === 'pregunta' || nodeTipo === 'root') {
      // Generate ANSWERS for questions
      return [
        new SystemMessage('Eres un asistente de mind mapping que ayuda a explorar temas a trav√©s de pensamiento estructurado. Genera respuestas concisas y espec√≠ficas.'),
        new HumanMessage(`Genera ${count} respuestas concisas y distintas a la siguiente pregunta:

"${nodeText}"

Requisitos:
- Cada respuesta debe tener m√°ximo 5-15 palabras
- Las respuestas deben explorar diferentes aspectos o perspectivas
- Hazlas espec√≠ficas y accionables
- Devuelve SOLO las respuestas, una por l√≠nea, sin numeraci√≥n ni vi√±etas
- Usa espa√±ol si la pregunta est√° en espa√±ol, ingl√©s si est√° en ingl√©s

Formato: Una respuesta por l√≠nea`)
      ];
    } else if (nodeTipo === 'respuesta') {
      // Generate QUESTIONS for answers
      return [
        new SystemMessage('Eres un asistente de mind mapping que ayuda a profundizar la exploraci√≥n mediante preguntas. Genera preguntas provocadoras de seguimiento.'),
        new HumanMessage(`Bas√°ndote en la siguiente afirmaci√≥n o respuesta:

"${nodeText}"

Genera ${count} preguntas de seguimiento que exploren este tema m√°s profundamente.

Requisitos:
- Cada pregunta debe tener m√°ximo 5-15 palabras
- Las preguntas deben explorar diferentes √°ngulos (por qu√©, c√≥mo, qu√© pasar√≠a si, consecuencias, etc.)
- Hazlas provocadoras y espec√≠ficas
- Devuelve SOLO las preguntas, una por l√≠nea, sin numeraci√≥n ni vi√±etas
- Usa espa√±ol si la afirmaci√≥n est√° en espa√±ol, ingl√©s si est√° en ingl√©s

Formato: Una pregunta por l√≠nea`)
      ];
    } else {
      throw new Error(`Unknown node type: ${nodeTipo}`);
    }
  }

  /**
   * Parse LLM response into array of node objects
   * @private
   */
  _parseResponse(aiResponse) {
    if (!aiResponse || typeof aiResponse !== 'string') {
      return [];
    }

    // Split by newlines and clean up
    const lines = aiResponse
      .split('\n')
      .map(line => line.trim())
      .filter(line => line.length > 0)
      .map(line => {
        // Remove common prefixes (1., -, *, ‚Ä¢, etc.)
        return line.replace(/^[\d\-\*\‚Ä¢\.]+\s*/, '').trim();
      })
      .filter(line => line.length > 0);

    return lines.map(text => ({ text }));
  }
}

let instance = null;

class OpenAIServiceProxy {
  constructor() {
    this.serviceInstance = null;
  }

  getInstance() {
    if (!this.serviceInstance) {
      this.serviceInstance = new OpenAIService();
    }
    return this.serviceInstance;
  }

  generateNodes(nodeText, nodeTipo, count) {
    return this.getInstance().generateNodes(nodeText, nodeTipo, count);
  }
}

export default new OpenAIServiceProxy();
